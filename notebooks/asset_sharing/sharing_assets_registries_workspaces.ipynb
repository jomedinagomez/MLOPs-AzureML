{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Share components, environments and models across workspaces\n",
        "\n",
        "This is the companion notebook for the article on sharing components, environments and models across workspaces: https://learn.microsoft.com/en-us/azure/machine-learning/how-to-share-models-pipelines-across-workspaces-with-registries \n",
        "\n",
        "### Prerequisites\n",
        "Review the prerequisites section in the article: https://learn.microsoft.com/en-us/azure/machine-learning/how-to-share-models-pipelines-across-workspaces-with-registries?tabs=python#prerequisites. To summarize, in addition to the Python SDK, you need an AzureML registry and an AzureML workspace in a region that is supported by the workspace.\n",
        "\n",
        "\n",
        "### Scenarios\n",
        "\n",
        "There are two scenarios where you'd want to use the same set of models, components and environments in multiple workspaces:\n",
        "\n",
        "* Cross-workspace MLOps: You're training a model in a dev workspace and need to deploy it to test and prod workspaces. In this case you, want to have end-to-end lineage between endpoints to which the model is deployed in test or prod workspaces and the training job, metrics, code, data and environment that was used to train the model in the dev workspace.\n",
        "* Share and reuse models and pipelines across different teams: Sharing and reuse improve collaboration and productivity. In this scenario, you may want to publish a trained model and the associated components and environments used to train it to a central catalog. From there, colleagues from other teams can search and reuse the assets you shared in their own experiments.\n",
        "\n",
        "### Goals\n",
        "* Create an environment and component in the registry.\n",
        "* Use the component from registry to submit a model training job in a workspace.\n",
        "* Register the trained model in the registry.\n",
        "* Deploy the model from the registry to an online-endpoint in the workspace, then submit an inference request.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1752695400212
        }
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential, ManagedIdentityCredential\n",
        "\n",
        "from azure.ai.ml import MLClient, Input, Output\n",
        "from azure.ai.ml.dsl import pipeline\n",
        "from azure.ai.ml import load_component\n",
        "from azure.ai.ml.entities import (\n",
        "    Environment,\n",
        "    BuildContext,\n",
        "    Model,\n",
        "    ManagedOnlineEndpoint,\n",
        "    ManagedOnlineDeployment,\n",
        "    CodeConfiguration,\n",
        ")\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "import time, datetime, os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(override=True)\n",
        "\n",
        "SUBSCRIPTION_ID = os.environ[\"SUBSCRIPTION_ID\"]\n",
        "RESOURCE_GROUP = os.environ[\"RESOURCE_GROUP\"]\n",
        "AML_WORKSPACE_NAME = os.environ[\"AML_WORKSPACE_NAME\"]\n",
        "EXTERNAL_REGISTRY_NAME = \"publicregistry\"#os.environ[\"EXTERNAL_REGISTRY_NAME\"]\n",
        "USER_ASSIGNED_IDENTITY_NAME = os.environ[\"USER_ASSIGNED_IDENTITY_NAME\"]\n",
        "USER_ASSIGNED_IDENTITY_RESOURCE_GROUP = os.environ[\"USER_ASSIGNED_IDENTITY_RESOURCE_GROUP\"]\n",
        "USER_ASSIGNED_IDENTITY_CLIENT_ID = os.environ[\"USER_ASSIGNED_IDENTITY_CLIENT_ID\"]\n",
        "# print the sdk version - you many want to share this in the issue you will report if parts of this notebook don't work\n",
        "#!pip show azure-ai-ml"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup authentication\n",
        "\n",
        "We are using `DefaultAzureCredential` to get access to workspace. When an access token is needed, it requests one using multiple identities(`EnvironmentCredential, ManagedIdentityCredential, SharedTokenCacheCredential, VisualStudioCodeCredential, AzureCliCredential, AzurePowerShellCredential`) in turn, stopping when one provides a token.\n",
        "Reference [here](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity.defaultazurecredential?view=azure-python) for more information.\n",
        "\n",
        "`DefaultAzureCredential` should be capable of handling most Azure SDK authentication scenarios. \n",
        "Reference [here](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity?view=azure-python) for all available credentials if it does not work for you.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connect to a workspace and registry\n",
        "\n",
        "Most samples create one client to connect to the workspace. However, in this sample, you need two clients. First client, called `ml_client_workspace`, will be used to connect to a workspace and run jobs or deploy endpoints. Second client, called `ml_client_registry` will be used to connect to the registry to create components, environments and models.\n",
        "\n",
        "Replace the following:\n",
        "* `<SUBSCRIPTION_ID>`\n",
        "* `<RESOURCE_GROUP>`\n",
        "* `<AML_WORKSPACE_NAME>`\n",
        "* `<REGISTRY_NAME>`\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x000001BB86752A50>,\n",
            "         subscription_id=5784b6a5-de3f-4fa4-8b8f-e5bb70ff6b25,\n",
            "         resource_group_name=rg-aml-ws-dev-cc,\n",
            "         workspace_name=amldevcc002)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Overriding of current TracerProvider is not allowed\n",
            "Overriding of current LoggerProvider is not allowed\n",
            "Overriding of current MeterProvider is not allowed\n",
            "Attempting to instrument while already instrumented\n",
            "Attempting to instrument while already instrumented\n",
            "Attempting to instrument while already instrumented\n",
            "Attempting to instrument while already instrumented\n",
            "Attempting to instrument while already instrumented\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x000001BB86752A50>,\n",
            "         subscription_id=5784b6a5-de3f-4fa4-8b8f-e5bb70ff6b25,\n",
            "         resource_group_name=openexternalci,\n",
            "         workspace_name=None)\n"
          ]
        }
      ],
      "source": [
        "ml_client_workspace = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=SUBSCRIPTION_ID,\n",
        "    resource_group_name=RESOURCE_GROUP,\n",
        "    workspace_name=AML_WORKSPACE_NAME,\n",
        ")\n",
        "print(ml_client_workspace)\n",
        "\n",
        "ml_client_registry = MLClient(credential=credential, registry_name=EXTERNAL_REGISTRY_NAME)\n",
        "print(ml_client_registry)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a version number and setup root directory \n",
        "Make sure that you set the version number to something unique if this notebook has been run before. You can use the timestamp to generate a unique version number, the sample code for which is commented out. This will prevent any name and version conflicts when creating assets.\n",
        "\n",
        "Set the root directory in which the YAML definitions of the components, environments, etc. are present."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "version:  1753806783\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import sys\n",
        "\n",
        "# version = str(123456)\n",
        "version = str(int(time.time()))\n",
        "print(\"version: \", version)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create model in registry\n",
        "\n",
        "You will now obtain the model trained by the pipeline job in the above step and create the model in the registry. For completeness, we are showing two options here.\n",
        "* First option shows to create a model in registry from job output without downloading it. This option is recommended when you want to track the lineage between the training job and the model. You will create a model directly from the job output (without downloading it) in your workspace and then copy the model from workspace to registry. \n",
        "* Second option shows how to create a model in registry from local files. In this case you will download the model from the job output. This option is helpful if you have an existing model from some external source and want to host it in the registry to be shared with many workspaces.\n",
        "\n",
        "Review this notebook to learn the different model types and how to create them in a workspace: [../../assets/model/model.ipynb](../model/model.ipynb). In the below example, you will work with a `mlflow_model` that will help you deploy this model for inference without writing any scoring scripts.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create model from local files \n",
        "Step b: Create a model in registry from files in a local folder. Note that you use the `ml_client_registry` client to create the model in registry. The syntax for creating model in a workspace or registry are identical. You just use a client that is specific to the target - workspace or registry.\n",
        "\n",
        "> **Warning:** If you have successfully created a model in registry in the previous steps, this section will fail as the model with the name and version will already exist. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "description: MLflow model created from local path\n",
            "name: nyc-taxi-model\n",
            "path: C:\\Users\\jomedin\\Documents\\MLOPs-AzureML\\notebooks\\asset_sharing\\artifacts\\model\n",
            "properties: {}\n",
            "tags: {}\n",
            "type: mlflow_model\n",
            "version: '1753806783'\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Subtype value SAS has no mapping, use base class DataReferenceCredentialDto.\n",
            "\u001b[32mUploading model (0.0 MBs): 100%|##########| 2666/2666 [00:00<00:00, 31753.56it/s]\n",
            "\u001b[39m\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Model({'job_name': None, 'intellectual_property': None, 'system_metadata': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'nyc-taxi-model', 'description': 'MLflow model created from local path', 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': 'azureml://registries/publicregistry/models/nyc-taxi-model/versions/1753806783', 'Resource__source_path': '', 'base_path': 'c:\\\\Users\\\\jomedin\\\\Documents\\\\MLOPs-AzureML\\\\notebooks\\\\asset_sharing', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x000001BB887B07D0>, 'serialize': <msrest.serialization.Serializer object at 0x000001BB88797620>, 'version': '1753806783', 'latest_version': None, 'path': 'https://74d982b71cb.blob.core.windows.net/publicregi-cb264f95-f8b9-5ea5-bc0a-3aa94e900fc6/model', 'datastore': None, 'utc_time_created': None, 'flavors': {'python_function': {'env': 'conda.yaml', 'loader_module': 'mlflow.sklearn', 'model_path': 'model.pkl', 'predict_fn': 'predict', 'python_version': '3.8.13'}, 'sklearn': {'code': '', 'pickled_model': 'model.pkl', 'serialization_format': 'cloudpickle', 'sklearn_version': '0.24.1'}}, 'arm_type': 'model_version', 'type': 'mlflow_model', 'stage': None})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# this section is optional, will fail if this model name and version is already created in the registry in the previous steps\n",
        "mlflow_model = Model(\n",
        "    path=\"./artifacts/model/\",\n",
        "    type=AssetTypes.MLFLOW_MODEL,\n",
        "    name=\"nyc-taxi-model\",\n",
        "    version= version,\n",
        "    description=\"MLflow model created from local path\",\n",
        ")\n",
        "print(mlflow_model)\n",
        "#ml_client_workspace.models.create_or_update(mlflow_model)\n",
        "ml_client_registry.models.create_or_update(mlflow_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create model in workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "description: MLflow model created from local path\n",
            "name: nyc-taxi-model\n",
            "path: /mnt/batch/tasks/shared/LS_root/mounts/clusters/azuremlci/code/Users/admin/external_registry/artifacts/model\n",
            "properties: {}\n",
            "tags: {}\n",
            "type: mlflow_model\n",
            "version: '1753488311'\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Model({'job_name': None, 'intellectual_property': None, 'system_metadata': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'nyc-taxi-model', 'description': 'MLflow model created from local path', 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/5784b6a5-de3f-4fa4-8b8f-e5bb70ff6b25/resourceGroups/PublicAzureML/providers/Microsoft.MachineLearningServices/workspaces/pazuremlregistrytest/models/nyc-taxi-model/versions/1753488311', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/azuremlci/code/Users/admin/external_registry', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x75063e99fe10>, 'serialize': <msrest.serialization.Serializer object at 0x75063e957150>, 'version': '1753488311', 'latest_version': None, 'path': 'azureml://subscriptions/5784b6a5-de3f-4fa4-8b8f-e5bb70ff6b25/resourceGroups/PublicAzureML/workspaces/pazuremlregistrytest/datastores/workspaceblobstore/paths/LocalUpload/beaf4dff7bd507b2efc4d854506d9a608734143a0118f0b24568f96a7a57852a/model', 'datastore': None, 'utc_time_created': None, 'flavors': {'python_function': {'env': 'conda.yaml', 'loader_module': 'mlflow.sklearn', 'model_path': 'model.pkl', 'predict_fn': 'predict', 'python_version': '3.8.13'}, 'sklearn': {'code': '', 'pickled_model': 'model.pkl', 'serialization_format': 'cloudpickle', 'sklearn_version': '0.24.1'}}, 'arm_type': 'model_version', 'type': 'mlflow_model', 'stage': 'Development'})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# this section is optional, will fail if this model name and version is already created in the registry in the previous steps\n",
        "mlflow_model = Model(\n",
        "    path=\"./artifacts/model/\",\n",
        "    type=AssetTypes.MLFLOW_MODEL,\n",
        "    name=\"nyc-taxi-model\",\n",
        "    version= version,\n",
        "    description=\"MLflow model created from local path\",\n",
        ")\n",
        "print(mlflow_model)\n",
        "ml_client_workspace.models.create_or_update(mlflow_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Share model from workspace to registry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Method share: This is an experimental method, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Model({'job_name': None, 'intellectual_property': None, 'system_metadata': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'nyc-taxi-model-new', 'description': 'MLflow model created from local path', 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': 'azureml://registries/publicregistry/models/nyc-taxi-model-new/versions/1753488311', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/azuremlci/code/Users/admin/external_registry', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x75063d55c640>, 'serialize': <msrest.serialization.Serializer object at 0x75063dffcbb0>, 'version': '1753488311', 'latest_version': None, 'path': 'https://74d982b71cb.blob.core.windows.net/publicregi-6bff3d61-5e25-5de4-b0a1-a26950d059af/LocalUpload/beaf4dff7bd507b2efc4d854506d9a608734143a0118f0b24568f96a7a57852a/model', 'datastore': None, 'utc_time_created': None, 'flavors': {'python_function': {'env': 'conda.yaml', 'loader_module': 'mlflow.sklearn', 'model_path': 'model.pkl', 'predict_fn': 'predict', 'python_version': '3.8.13'}, 'sklearn': {'code': '', 'pickled_model': 'model.pkl', 'serialization_format': 'cloudpickle', 'sklearn_version': '0.24.1'}}, 'arm_type': 'model_version', 'type': 'mlflow_model', 'stage': None})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ml_client_workspace.models.share(\n",
        "    name=\"nyc-taxi-model\",\n",
        "    version=version,\n",
        "    registry_name=EXTERNAL_REGISTRY_NAME,\n",
        "    share_with_name=\"nyc-taxi-model-new\",\n",
        "    share_with_version=version,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create environment in workspace and then share it to registry"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create environment in workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Environment({'arm_type': 'environment_version', 'latest_version': None, 'image': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04', 'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'docker-image-plus-conda-example', 'description': 'Environment created from a Docker image plus Conda environment.', 'tags': {}, 'properties': {'azureml.labels': 'latest'}, 'print_as_yaml': False, 'id': '/subscriptions/5784b6a5-de3f-4fa4-8b8f-e5bb70ff6b25/resourceGroups/PublicAzureML/providers/Microsoft.MachineLearningServices/workspaces/pazuremlregistrytest/environments/docker-image-plus-conda-example/versions/1', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/azuremlci/code/Users/admin/external_registry', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x75063f37a0f0>, 'serialize': <msrest.serialization.Serializer object at 0x75063e9567b0>, 'version': '1', 'conda_file': {'channels': ['defaults'], 'dependencies': ['python=3.8', 'pip', {'pip': ['pandas', 'numpy', 'scikit-learn', 'joblib', 'azureml-inference-server-http']}], 'name': 'multimodel'}, 'build': None, 'inference_config': None, 'os_type': 'Linux', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': '{\\n  \"channels\": [\\n    \"defaults\"\\n  ],\\n  \"dependencies\": [\\n    \"python=3.8\",\\n    \"pip\",\\n    {\\n      \"pip\": [\\n        \"pandas\",\\n        \"numpy\",\\n        \"scikit-learn\",\\n        \"joblib\",\\n        \"azureml-inference-server-http\"\\n      ]\\n    }\\n  ],\\n  \"name\": \"multimodel\"\\n}'})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env_docker_conda = Environment(\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n",
        "    conda_file=\"environment/online-endpoints-multimodel.yml\",\n",
        "    name=\"docker-image-plus-conda-example\",\n",
        "    description=\"Environment created from a Docker image plus Conda environment.\",\n",
        ")\n",
        "ml_client_workspace.environments.create_or_update(env_docker_conda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Share environment to registry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ml_client_workspace.environments.share(\n",
        "    name=\"docker-image-plus-conda-example\",\n",
        "    version=version,\n",
        "    registry_name=EXTERNAL_REGISTRY_NAME,\n",
        "    share_with_name=\"docker-image-plus-conda-example\",\n",
        "    share_with_version=version,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Deploy model from registry to online endpoint in workspace\n",
        "\n",
        "You will deploy the model to an online endpoint and submit some sample inference requests in this section. Note that just like jobs, endpoints that host models are specific to a workspace. You can deploy the a model from a registry to many workspaces. This helps you develop a model in `dev` workspace, share it with a registry, and then deploy it to `test` and `prod` workspaces. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get model from registry\n",
        "\n",
        "Use the `ml_client_registry` client to get the model created in previous section from the registry. The syntax for creating component in a workspace or registry are identical. You just use a client that is specific to the target - workspace or registry."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "creation_context:\n",
            "  created_at: '2025-07-17T04:11:36.075279+00:00'\n",
            "  created_by: 7eb0cccd-2e21-4ca5-abb7-c65071ac0203\n",
            "  created_by_type: Application\n",
            "  last_modified_at: '2025-07-17T04:11:35.571473+00:00'\n",
            "  last_modified_by: 7eb0cccd-2e21-4ca5-abb7-c65071ac0203\n",
            "  last_modified_by_type: Application\n",
            "description: MLflow model created from local path\n",
            "flavors:\n",
            "  python_function:\n",
            "    env: conda.yaml\n",
            "    loader_module: mlflow.sklearn\n",
            "    model_path: model.pkl\n",
            "    predict_fn: predict\n",
            "    python_version: 3.8.13\n",
            "  sklearn:\n",
            "    code: ''\n",
            "    pickled_model: model.pkl\n",
            "    serialization_format: cloudpickle\n",
            "    sklearn_version: 0.24.1\n",
            "id: azureml://registries/publicregistry/models/nyc-taxi-model/versions/1752725482\n",
            "name: nyc-taxi-model\n",
            "path: https://74d982b71cb.blob.core.windows.net/publicregi-1fd23ebd-f2b7-51d7-be28-0c7b5183df5d/model\n",
            "properties: {}\n",
            "tags: {}\n",
            "type: mlflow_model\n",
            "version: '1752725482'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "mlflow_model_from_registry = ml_client_registry.models.get(\n",
        "    name=\"nyc-taxi-model\", version=version\n",
        ")\n",
        "print(mlflow_model_from_registry)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create an online endpoint \n",
        "\n",
        "Create Identity configuration for User Assigned Identity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://github.com/MicrosoftDocs/azure-ai-docs/blob/main/articles/machine-learning/how-to-identity-based-service-authentication.md\n",
        "# https://learn.microsoft.com/en-us/azure/machine-learning/how-to-identity-based-service-authentication?view=azureml-api-2&tabs=python#create-compute-with-managed-identity-to-access-docker-images-for-training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import IdentityConfiguration, ManagedIdentityConfiguration\n",
        "from azure.ai.ml.constants import ManagedServiceIdentityType\n",
        "\n",
        "uai = USER_ASSIGNED_IDENTITY_NAME  # replace with your user-assigned managed identity name\n",
        "resource_id = f\"/subscriptions/{SUBSCRIPTION_ID}/resourcegroups/{USER_ASSIGNED_IDENTITY_RESOURCE_GROUP}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{uai}\"\n",
        "# Create an identity configuration from the user-assigned managed identity\n",
        "managed_identity = ManagedIdentityConfiguration(resource_id=resource_id)\n",
        "identity_config = IdentityConfiguration(type = ManagedServiceIdentityType.USER_ASSIGNED, user_assigned_identities=[managed_identity])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create an online endpoint to deploy the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Readonly attribute principal_id will be ignored in class <class 'azure.ai.ml._restclient.v2022_05_01.models._models_py3.ManagedServiceIdentity'>\n",
            "Readonly attribute tenant_id will be ignored in class <class 'azure.ai.ml._restclient.v2022_05_01.models._models_py3.ManagedServiceIdentity'>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://endpoint-1752725482.eastus2.inference.ml.azure.com/score', 'openapi_uri': 'https://endpoint-1752725482.eastus2.inference.ml.azure.com/swagger.json', 'name': 'endpoint-1752725482', 'description': 'this is a sample online endpoint for mlflow model', 'tags': {}, 'properties': {'createdBy': '7eb0cccd-2e21-4ca5-abb7-c65071ac0203', 'createdAt': '2025-07-17T04:12:08.018487+0000', 'lastModifiedAt': '2025-07-17T04:12:08.018487+0000', 'azureml.onlineendpointid': '/subscriptions/5784b6a5-de3f-4fa4-8b8f-e5bb70ff6b25/resourcegroups/publicazureml/providers/microsoft.machinelearningservices/workspaces/pazuremlregistrytest/onlineendpoints/endpoint-1752725482', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/5784b6a5-de3f-4fa4-8b8f-e5bb70ff6b25/providers/Microsoft.MachineLearningServices/locations/eastus2/mfeOperationsStatus/oeidp:850d046a-3781-47a9-86d9-5475e26d52f7:7160bdfa-d201-4431-a509-5d4be7eac06a?api-version=2022-02-01-preview'}, 'print_as_yaml': False, 'id': '/subscriptions/5784b6a5-de3f-4fa4-8b8f-e5bb70ff6b25/resourceGroups/PublicAzureML/providers/Microsoft.MachineLearningServices/workspaces/pazuremlregistrytest/onlineEndpoints/endpoint-1752725482', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/uaici/code/Users/admin/external_registry', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x75ae5f161780>, 'auth_mode': 'key', 'location': 'eastus2', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x75ae5c8b3680>, 'traffic': {}, 'mirror_traffic': {}, 'kind': 'Managed'})"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "online_endpoint_name = \"endpoint-\" + version\n",
        "# create an online endpoint\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=online_endpoint_name,\n",
        "    description=\"this is a sample online endpoint for mlflow model\",\n",
        "    auth_mode=\"key\",\n",
        "    identity=identity_config,\n",
        ")\n",
        "ml_client_workspace.begin_create_or_update(endpoint).result()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Deploy the model from registry to the online endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Check: endpoint endpoint-1752725482 exists\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "..............................."
          ]
        }
      ],
      "source": [
        "# create a demo deployment\n",
        "demo_deployment = ManagedOnlineDeployment(\n",
        "    name=\"demo\",\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    model=mlflow_model_from_registry.id,\n",
        "    instance_type=\"Standard_F4s_v2\",\n",
        "    instance_count=1,\n",
        ")\n",
        "ml_client_workspace.online_deployments.begin_create_or_update(demo_deployment).result()\n",
        "\n",
        "endpoint.traffic = {\"demo\": 100}\n",
        "ml_client_workspace.begin_create_or_update(endpoint).result()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test the deployment\n",
        "\n",
        "This section needs a sample request file `scoring-data.json` which is available in the root directory initialized in the beginning of this notebook: [../../../cli/jobs/pipelines-with-components/nyc_taxi_data_regression/scoring-data.json](../../../cli/jobs/pipelines-with-components/nyc_taxi_data_regression/scoring-data.json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'[5.936981839396367, 21.51612674922012, 55.471569384161285]'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test the  deployment with some sample data\n",
        "ml_client_workspace.online_endpoints.invoke(\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    deployment_name=\"demo\",\n",
        "    request_file=\"scoring-data.json\",\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Clean up resources\n",
        "\n",
        "#### delete online endpoint "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "online_endpoint_name: endpoint-1752701048\n",
            "...................."
          ]
        }
      ],
      "source": [
        "print(f\"online_endpoint_name: {online_endpoint_name}\")\n",
        "ml_client_workspace.online_endpoints.begin_delete(name=online_endpoint_name).result()"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "mlops-azureml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
