{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==2.3.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from -r ../../../requirements.txt (line 2)) (2.3.1)\n",
      "Requirement already satisfied: pandas==2.3.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from -r ../../../requirements.txt (line 3)) (2.3.1)\n",
      "Requirement already satisfied: matplotlib==3.10.3 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from -r ../../../requirements.txt (line 4)) (3.10.3)\n",
      "Requirement already satisfied: scikit-learn==1.7.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from -r ../../../requirements.txt (line 5)) (1.7.1)\n",
      "Requirement already satisfied: scipy==1.16.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from -r ../../../requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: jupyterlab in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from -r ../../../requirements.txt (line 9)) (4.4.5)\n",
      "Requirement already satisfied: ipykernel==6.30.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from -r ../../../requirements.txt (line 10)) (6.30.0)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from -r ../../../requirements.txt (line 11)) (0.1.7)\n",
      "Requirement already satisfied: azure-ai-ml==1.28.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from -r ../../../requirements.txt (line 14)) (1.28.1)\n",
      "Requirement already satisfied: azure-identity==1.24.0b1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from -r ../../../requirements.txt (line 15)) (1.24.0b1)\n",
      "Requirement already satisfied: azureml-mlflow==1.60.0.post1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from -r ../../../requirements.txt (line 16)) (1.60.0.post1)\n",
      "Requirement already satisfied: mlflow==2.22.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from -r ../../../requirements.txt (line 19)) (2.22.1)\n",
      "Requirement already satisfied: azureml-ai-monitoring~=0.1.0b1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from -r ../../../requirements.txt (line 22)) (0.1.0b4)\n",
      "Requirement already satisfied: opentelemetry-api==1.31.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from -r ../../../requirements.txt (line 25)) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-sdk==1.31.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from -r ../../../requirements.txt (line 26)) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.52b1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from -r ../../../requirements.txt (line 27)) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-requests==0.52b1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from -r ../../../requirements.txt (line 28)) (0.52b1)\n",
      "Requirement already satisfied: pyarrow==19.0.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from -r ../../../requirements.txt (line 31)) (19.0.1)\n",
      "Requirement already satisfied: python-dotenv==1.1.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from -r ../../../requirements.txt (line 32)) (1.1.1)\n",
      "Requirement already satisfied: requests==2.32.4 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from -r ../../../requirements.txt (line 33)) (2.32.4)\n",
      "Requirement already satisfied: tqdm==4.67.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from -r ../../../requirements.txt (line 34)) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from pandas==2.3.1->-r ../../../requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from pandas==2.3.1->-r ../../../requirements.txt (line 3)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from pandas==2.3.1->-r ../../../requirements.txt (line 3)) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from matplotlib==3.10.3->-r ../../../requirements.txt (line 4)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from matplotlib==3.10.3->-r ../../../requirements.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from matplotlib==3.10.3->-r ../../../requirements.txt (line 4)) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from matplotlib==3.10.3->-r ../../../requirements.txt (line 4)) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from matplotlib==3.10.3->-r ../../../requirements.txt (line 4)) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from matplotlib==3.10.3->-r ../../../requirements.txt (line 4)) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from matplotlib==3.10.3->-r ../../../requirements.txt (line 4)) (3.2.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from scikit-learn==1.7.1->-r ../../../requirements.txt (line 5)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from scikit-learn==1.7.1->-r ../../../requirements.txt (line 5)) (3.6.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from ipykernel==6.30.0->-r ../../../requirements.txt (line 10)) (0.2.1)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from ipykernel==6.30.0->-r ../../../requirements.txt (line 10)) (1.8.16)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from ipykernel==6.30.0->-r ../../../requirements.txt (line 10)) (9.5.0)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from ipykernel==6.30.0->-r ../../../requirements.txt (line 10)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from ipykernel==6.30.0->-r ../../../requirements.txt (line 10)) (5.8.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from ipykernel==6.30.0->-r ../../../requirements.txt (line 10)) (1.6.0)\n",
      "Requirement already satisfied: psutil>=5.7 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from ipykernel==6.30.0->-r ../../../requirements.txt (line 10)) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=25 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from ipykernel==6.30.0->-r ../../../requirements.txt (line 10)) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from ipykernel==6.30.0->-r ../../../requirements.txt (line 10)) (6.5.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from ipykernel==6.30.0->-r ../../../requirements.txt (line 10)) (5.14.3)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.1.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (6.0.3)\n",
      "Requirement already satisfied: msrest<1.0.0,>=0.6.18 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (0.7.1)\n",
      "Requirement already satisfied: azure-core>=1.23.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (1.35.1)\n",
      "Requirement already satisfied: azure-mgmt-core>=1.3.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (1.6.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.5 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (3.26.1)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (4.25.1)\n",
      "Requirement already satisfied: strictyaml<2.0.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (1.7.3)\n",
      "Requirement already satisfied: colorama<1.0.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (0.4.6)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (2.10.1)\n",
      "Requirement already satisfied: azure-storage-blob>=12.10.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (12.19.0)\n",
      "Requirement already satisfied: azure-storage-file-share in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (12.22.0)\n",
      "Requirement already satisfied: azure-storage-file-datalake>=12.2.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (12.14.0)\n",
      "Requirement already satisfied: pydash<9.0.0,>=6.0.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (8.0.5)\n",
      "Requirement already satisfied: isodate<1.0.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (0.7.2)\n",
      "Requirement already satisfied: azure-common>=1.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (1.1.28)\n",
      "Requirement already satisfied: typing-extensions<5.0.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (4.15.0)\n",
      "Requirement already satisfied: azure-monitor-opentelemetry in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (1.6.12)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (1.17.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azure-identity==1.24.0b1->-r ../../../requirements.txt (line 15)) (46.0.2)\n",
      "Requirement already satisfied: msal>=1.30.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azure-identity==1.24.0b1->-r ../../../requirements.txt (line 15)) (1.34.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azure-identity==1.24.0b1->-r ../../../requirements.txt (line 15)) (1.3.1)\n",
      "Requirement already satisfied: jsonpickle<5.0.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azureml-mlflow==1.60.0.post1->-r ../../../requirements.txt (line 16)) (4.1.1)\n",
      "Requirement already satisfied: mlflow-skinny<3.0.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azureml-mlflow==1.60.0.post1->-r ../../../requirements.txt (line 16)) (2.22.1)\n",
      "Requirement already satisfied: Flask<4 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from mlflow==2.22.1->-r ../../../requirements.txt (line 19)) (3.1.2)\n",
      "Requirement already satisfied: Jinja2<4,>=3.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from mlflow==2.22.1->-r ../../../requirements.txt (line 19)) (3.1.6)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from mlflow==2.22.1->-r ../../../requirements.txt (line 19)) (1.16.5)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from mlflow==2.22.1->-r ../../../requirements.txt (line 19)) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from mlflow==2.22.1->-r ../../../requirements.txt (line 19)) (3.4.3)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from mlflow==2.22.1->-r ../../../requirements.txt (line 19)) (3.9)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from mlflow==2.22.1->-r ../../../requirements.txt (line 19)) (2.0.43)\n",
      "Requirement already satisfied: waitress<4 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from mlflow==2.22.1->-r ../../../requirements.txt (line 19)) (3.0.2)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from mlflow-skinny<3.0.0->azureml-mlflow==1.60.0.post1->-r ../../../requirements.txt (line 16)) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from mlflow-skinny<3.0.0->azureml-mlflow==1.60.0.post1->-r ../../../requirements.txt (line 16)) (8.3.0)\n",
      "Requirement already satisfied: cloudpickle<4 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from mlflow-skinny<3.0.0->azureml-mlflow==1.60.0.post1->-r ../../../requirements.txt (line 16)) (3.1.1)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from mlflow-skinny<3.0.0->azureml-mlflow==1.60.0.post1->-r ../../../requirements.txt (line 16)) (0.67.0)\n",
      "Requirement already satisfied: fastapi<1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from mlflow-skinny<3.0.0->azureml-mlflow==1.60.0.post1->-r ../../../requirements.txt (line 16)) (0.118.2)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from mlflow-skinny<3.0.0->azureml-mlflow==1.60.0.post1->-r ../../../requirements.txt (line 16)) (3.1.45)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from mlflow-skinny<3.0.0->azureml-mlflow==1.60.0.post1->-r ../../../requirements.txt (line 16)) (8.6.1)\n",
      "Requirement already satisfied: protobuf<7,>=3.12.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from mlflow-skinny<3.0.0->azureml-mlflow==1.60.0.post1->-r ../../../requirements.txt (line 16)) (6.32.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.10.8 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from mlflow-skinny<3.0.0->azureml-mlflow==1.60.0.post1->-r ../../../requirements.txt (line 16)) (2.12.0)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from mlflow-skinny<3.0.0->azureml-mlflow==1.60.0.post1->-r ../../../requirements.txt (line 16)) (0.5.3)\n",
      "Requirement already satisfied: uvicorn<1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from mlflow-skinny<3.0.0->azureml-mlflow==1.60.0.post1->-r ../../../requirements.txt (line 16)) (0.37.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from opentelemetry-api==1.31.1->-r ../../../requirements.txt (line 25)) (1.2.18)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from opentelemetry-sdk==1.31.1->-r ../../../requirements.txt (line 26)) (0.52b1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from requests==2.32.4->-r ../../../requirements.txt (line 33)) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from requests==2.32.4->-r ../../../requirements.txt (line 33)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from requests==2.32.4->-r ../../../requirements.txt (line 33)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from requests==2.32.4->-r ../../../requirements.txt (line 33)) (2025.10.5)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from opentelemetry-instrumentation==0.52b1->-r ../../../requirements.txt (line 27)) (1.17.3)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.52b1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from opentelemetry-instrumentation-requests==0.52b1->-r ../../../requirements.txt (line 28)) (0.52b1)\n",
      "Requirement already satisfied: Mako in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow==2.22.1->-r ../../../requirements.txt (line 19)) (1.3.10)\n",
      "Requirement already satisfied: google-auth~=2.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny<3.0.0->azureml-mlflow==1.60.0.post1->-r ../../../requirements.txt (line 16)) (2.41.1)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from docker<8,>=4.0.0->mlflow==2.22.1->-r ../../../requirements.txt (line 19)) (311)\n",
      "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from fastapi<1->mlflow-skinny<3.0.0->azureml-mlflow==1.60.0.post1->-r ../../../requirements.txt (line 16)) (0.48.0)\n",
      "Requirement already satisfied: blinker>=1.9.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from Flask<4->mlflow==2.22.1->-r ../../../requirements.txt (line 19)) (1.9.0)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from Flask<4->mlflow==2.22.1->-r ../../../requirements.txt (line 19)) (2.2.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from Flask<4->mlflow==2.22.1->-r ../../../requirements.txt (line 19)) (3.0.3)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from Flask<4->mlflow==2.22.1->-r ../../../requirements.txt (line 19)) (3.1.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from gitpython<4,>=3.1.9->mlflow-skinny<3.0.0->azureml-mlflow==1.60.0.post1->-r ../../../requirements.txt (line 16)) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny<3.0.0->azureml-mlflow==1.60.0.post1->-r ../../../requirements.txt (line 16)) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny<3.0.0->azureml-mlflow==1.60.0.post1->-r ../../../requirements.txt (line 16)) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny<3.0.0->azureml-mlflow==1.60.0.post1->-r ../../../requirements.txt (line 16)) (4.9.1)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from graphene<4->mlflow==2.22.1->-r ../../../requirements.txt (line 19)) (3.2.6)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from graphene<4->mlflow==2.22.1->-r ../../../requirements.txt (line 19)) (3.2.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny<3.0.0->azureml-mlflow==1.60.0.post1->-r ../../../requirements.txt (line 16)) (3.23.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (0.27.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from msrest<1.0.0,>=0.6.18->azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (2.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from pydantic<3,>=1.10.8->mlflow-skinny<3.0.0->azureml-mlflow==1.60.0.post1->-r ../../../requirements.txt (line 16)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from pydantic<3,>=1.10.8->mlflow-skinny<3.0.0->azureml-mlflow==1.60.0.post1->-r ../../../requirements.txt (line 16)) (2.41.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from pydantic<3,>=1.10.8->mlflow-skinny<3.0.0->azureml-mlflow==1.60.0.post1->-r ../../../requirements.txt (line 16)) (0.4.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny<3.0.0->azureml-mlflow==1.60.0.post1->-r ../../../requirements.txt (line 16)) (0.6.1)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from sqlalchemy<3,>=1.4.0->mlflow==2.22.1->-r ../../../requirements.txt (line 19)) (3.2.4)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from starlette<0.49.0,>=0.40.0->fastapi<1->mlflow-skinny<3.0.0->azureml-mlflow==1.60.0.post1->-r ../../../requirements.txt (line 16)) (4.11.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi<1->mlflow-skinny<3.0.0->azureml-mlflow==1.60.0.post1->-r ../../../requirements.txt (line 16)) (1.3.1)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from uvicorn<1->mlflow-skinny<3.0.0->azureml-mlflow==1.60.0.post1->-r ../../../requirements.txt (line 16)) (0.16.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jupyterlab->-r ../../../requirements.txt (line 9)) (2.0.5)\n",
      "Requirement already satisfied: httpx>=0.25.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jupyterlab->-r ../../../requirements.txt (line 9)) (0.28.1)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jupyterlab->-r ../../../requirements.txt (line 9)) (2.3.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jupyterlab->-r ../../../requirements.txt (line 9)) (2.17.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jupyterlab->-r ../../../requirements.txt (line 9)) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jupyterlab->-r ../../../requirements.txt (line 9)) (0.2.4)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jupyterlab->-r ../../../requirements.txt (line 9)) (78.1.1)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (25.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (7.16.6)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (5.10.4)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (0.23.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (3.0.2)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (1.9.0)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->-r ../../../requirements.txt (line 9)) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->-r ../../../requirements.txt (line 9)) (0.12.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (25.1.0)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from cryptography>=2.5->azure-identity==1.24.0b1->-r ../../../requirements.txt (line 15)) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from cffi>=2.0.0->cryptography>=2.5->azure-identity==1.24.0b1->-r ../../../requirements.txt (line 15)) (2.23)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from httpx>=0.25.0->jupyterlab->-r ../../../requirements.txt (line 9)) (1.0.9)\n",
      "Requirement already satisfied: decorator in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from ipython>=7.23.1->ipykernel==6.30.0->-r ../../../requirements.txt (line 10)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from ipython>=7.23.1->ipykernel==6.30.0->-r ../../../requirements.txt (line 10)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from ipython>=7.23.1->ipykernel==6.30.0->-r ../../../requirements.txt (line 10)) (0.19.2)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from ipython>=7.23.1->ipykernel==6.30.0->-r ../../../requirements.txt (line 10)) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from ipython>=7.23.1->ipykernel==6.30.0->-r ../../../requirements.txt (line 10)) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from ipython>=7.23.1->ipykernel==6.30.0->-r ../../../requirements.txt (line 10)) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel==6.30.0->-r ../../../requirements.txt (line 10)) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel==6.30.0->-r ../../../requirements.txt (line 10)) (0.8.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel==6.30.0->-r ../../../requirements.txt (line 10)) (4.3.7)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (4.0.0)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (0.1.1)\n",
      "Requirement already satisfied: fqdn in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (3.0.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (1.1.0)\n",
      "Requirement already satisfied: uri-template in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (24.11.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (4.14.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (3.1.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (1.5.1)\n",
      "Requirement already satisfied: webencodings in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (1.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (2.21.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest<1.0.0,>=0.6.18->azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (3.3.1)\n",
      "Requirement already satisfied: lark>=1.2.2 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (1.3.0)\n",
      "Requirement already satisfied: azure-core-tracing-opentelemetry~=1.0.0b11 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azure-monitor-opentelemetry->azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (1.0.0b12)\n",
      "Requirement already satisfied: azure-monitor-opentelemetry-exporter~=1.0.0b40 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azure-monitor-opentelemetry->azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (1.0.0b40)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-django<0.53b0,>=0.49b0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azure-monitor-opentelemetry->azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi<0.53b0,>=0.49b0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azure-monitor-opentelemetry->azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-flask<0.53b0,>=0.49b0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azure-monitor-opentelemetry->azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-psycopg2<0.53b0,>=0.49b0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azure-monitor-opentelemetry->azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-urllib<0.53b0,>=0.49b0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azure-monitor-opentelemetry->azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-urllib3<0.53b0,>=0.49b0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azure-monitor-opentelemetry->azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-resource-detector-azure~=0.1.4 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azure-monitor-opentelemetry->azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (0.1.5)\n",
      "Requirement already satisfied: fixedint==0.1.6 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from azure-monitor-opentelemetry-exporter~=1.0.0b40->azure-monitor-opentelemetry->azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (0.1.6)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-wsgi==0.52b1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from opentelemetry-instrumentation-django<0.53b0,>=0.49b0->azure-monitor-opentelemetry->azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.52b1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from opentelemetry-instrumentation-fastapi<0.53b0,>=0.49b0->azure-monitor-opentelemetry->azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (0.52b1)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.52b1->opentelemetry-instrumentation-fastapi<0.53b0,>=0.49b0->azure-monitor-opentelemetry->azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (3.10.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-dbapi==0.52b1 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from opentelemetry-instrumentation-psycopg2<0.53b0,>=0.49b0->azure-monitor-opentelemetry->azure-ai-ml==1.28.1->-r ../../../requirements.txt (line 14)) (0.52b1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (2.8)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ../../../requirements.txt (line 9)) (2.9.0.20251008)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel==6.30.0->-r ../../../requirements.txt (line 10)) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel==6.30.0->-r ../../../requirements.txt (line 10)) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in c:\\miniconda\\envs\\mlops\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel==6.30.0->-r ../../../requirements.txt (line 10)) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Installation command executed. Restart kernel if necessary.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # prefer parent path so notebook can be run from this folder\n",
    "    %pip install -r ../../../requirements.txt\n",
    "except Exception:\n",
    "    # fallback to local path\n",
    "    %pip install -r requirements.txt\n",
    "\n",
    "print(\"Installation command executed. Restart kernel if necessary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy a TensorFlow model served with TF Serving using a custom container in an online endpoint\n",
    "Learn how to deploy a custom container as an online endpoint in Azure Machine Learning.\n",
    "\n",
    "Custom container deployments can use web servers other than the default Python Flask server used by Azure Machine Learning. Users of these deployments can still take advantage of Azure Machine Learning's built-in monitoring, scaling, alerting, and authentication.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "* To use Azure Machine Learning, you must have an Azure subscription. If you don't have an Azure subscription, create a free account before you begin. Try the [free or paid version of Azure Machine Learning](https://azure.microsoft.com/free/).\n",
    "\n",
    "* Install and configure the [Python SDK v2](sdk/setup.sh).\n",
    "\n",
    "* You must have an Azure resource group, and you (or the service principal you use) must have Contributor access to it.\n",
    "\n",
    "* You must have an Azure Machine Learning workspace. \n",
    "\n",
    "* To deploy locally, you must install [Docker Engine](https://docs.docker.com/engine/install/) on your local computer. We highly recommend this option, so it's easier to debug issues.\n",
    "\n",
    "# 1. Connect to Azure Machine Learning Workspace\n",
    "\n",
    "The [workspace](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace) is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section we will connect to the workspace in which the job will be run.\n",
    "\n",
    "## 1.1. Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    Model,\n",
    "    Environment,\n",
    "    CodeConfiguration,\n",
    ")\n",
    "from azure.identity import DefaultAzureCredential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Configure workspace details and get a handle to the workspace\n",
    "\n",
    "To connect to a workspace, we need identifier parameters - a subscription, resource group and workspace name. We will use these details in the `MLClient` from `azure.ai.ml` to get a handle to the required Azure Machine Learning workspace. We use the default [default azure authentication](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity.defaultazurecredential?view=azure-python) for this tutorial. Check the [configuration notebook](../../jobs/configuration.ipynb) for more details on how to configure credentials and connect to a workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded workspace configuration:\n",
      "  SUBSCRIPTION_ID= \n",
      "  RESOURCE_GROUP= \n",
      "  WORKSPACE_NAME= \n"
     ]
    }
   ],
   "source": [
    "# Try to load workspace details from a local .env file (at notebooks/.env)\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Relative path from this notebook to the notebooks/.env file\n",
    "env_path = Path(\"../../../.env\")\n",
    "\n",
    "if env_path.exists():\n",
    "    with env_path.open() as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith(\"#\"):\n",
    "                continue\n",
    "            if \"=\" in line:\n",
    "                k, v = line.split(\"=\", 1)\n",
    "                os.environ[k.strip()] = v.strip()\n",
    "\n",
    "    # Read expected variables\n",
    "    subscription_id = os.environ.get(\"SUBSCRIPTION_ID\", \"\")\n",
    "    resource_group = os.environ.get(\"RESOURCE_GROUP\", \"\")\n",
    "    workspace = os.environ.get(\"WORKSPACE_NAME\", \"\")\n",
    "    appinsights_conn = os.environ.get(\"APPINSIGHTS_CONNECTION_STRING\", \"\")\n",
    "else:\n",
    "    print(f\".env file not found at {env_path}. Please set subscription_id, resource_group, workspace variables manually.\")\n",
    "\n",
    "print(\"Loaded workspace configuration:\")\n",
    "print(\"  SUBSCRIPTION_ID=\", \"\")\n",
    "print(\"  RESOURCE_GROUP=\", \"\")\n",
    "print(\"  WORKSPACE_NAME=\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current LoggerProvider is not allowed\n",
      "Overriding of current LoggerProvider is not allowed\n",
      "Overriding of current MeterProvider is not allowed\n",
      "Overriding of current MeterProvider is not allowed\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n"
     ]
    }
   ],
   "source": [
    "# get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Download a TensorFlow model\n",
    "\n",
    "BASE_PATH=endpoints/online/custom-container\n",
    "\n",
    "AML_MODEL_NAME=tfserving-mounted\n",
    "\n",
    "MODEL_NAME=half_plus_two\n",
    "\n",
    "MODEL_BASE_PATH=/var/azureml-app/azureml-models/$AML_MODEL_NAME/1\n",
    "\n",
    "Download and unzip a model that divides an input by two and adds 2 to the result\n",
    "\n",
    "`wget https://aka.ms/half_plus_two-model -O $BASE_PATH/half_plus_two.tar.gz`\n",
    "\n",
    "`tar -xvf $BASE_PATH/half_plus_two.tar.gz -C $BASE_PATH`\n",
    "\n",
    "In in this sample, we have already downloaded the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered model: tfservingcustom (version 1)\n"
     ]
    }
   ],
   "source": [
    "# Prepare TensorFlow Serving directory structure and register the model\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from azure.ai.ml.entities import Model\n",
    "\n",
    "original_model_dir = Path(\"half_plus_two\")\n",
    "serving_root = Path(\"tfservingcustom_serving\")\n",
    "version_subdir = serving_root / \"half_plus_two\" / \"1\"\n",
    "\n",
    "if serving_root.exists():\n",
    "    shutil.rmtree(serving_root)\n",
    "version_subdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for item in original_model_dir.iterdir():\n",
    "    destination = version_subdir / item.name\n",
    "    if item.is_dir():\n",
    "        shutil.copytree(item, destination)\n",
    "    else:\n",
    "        shutil.copy2(item, destination)\n",
    "\n",
    "registered_model = ml_client.models.create_or_update(\n",
    "    Model(\n",
    "        name=\"tfservingcustom\",\n",
    "        path=str(serving_root),\n",
    "        type=\"custom_model\",\n",
    "        description=\"TensorFlow SavedModel packaged for TF Serving\",\n",
    "        tags={\"framework\": \"tensorflow\", \"format\": \"saved_model\"},\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Registered model: {registered_model.name} (version {registered_model.version})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Test locally\n",
    "## 3.1 Use docker to run your image locally for testing\n",
    "Use docker to run your image locally for testing\n",
    "\n",
    "`docker run --rm -d -v $PWD/$BASE_PATH:$MODEL_BASE_PATH -p 8501:8501 \\\n",
    " -e MODEL_BASE_PATH=$MODEL_BASE_PATH -e MODEL_NAME=$MODEL_NAME \\\n",
    " --name=\"tfserving-test\" docker.io/tensorflow/serving:latest\n",
    "sleep 10`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Check that you can send liveness and scoring requests to the image\n",
    "First, check that the container is \"alive,\" meaning that the process inside the container is still running. You should get a 200 (OK) response.\n",
    "\n",
    "`curl -v http://localhost:8501/v1/models/$MODEL_NAME`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Check that you can get predictions about unlabeled data\n",
    "`curl --header \"Content-Type: application/json\" \\\n",
    "  --request POST \\\n",
    "  --data @$BASE_PATH/sample_request.json \\\n",
    "  http://localhost:8501/v1/models/$MODEL_NAME:predict`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Stop the image\n",
    "Now that you've tested locally, stop the image\n",
    "\n",
    "`docker stop tfserving-test`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Deploy your online endpoint to Azure\n",
    "Next, deploy your online endpoint to Azure.\n",
    "\n",
    "## 4.1 Configure online endpoint\n",
    "`endpoint_name`: The name of the endpoint. It must be unique in the Azure region. Naming rules are defined under [managed online endpoint limits](https://docs.microsoft.com/azure/machine-learning/how-to-manage-quotas#azure-machine-learning-managed-online-endpoints-preview).\n",
    "\n",
    "`auth_mode` : Use `key` for key-based authentication. Use `aml_token` for Azure Machine Learning token-based authentication. A `key` does not expire, but `aml_token` does expire. \n",
    "\n",
    "Optionally, you can add description, tags to your endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a unique endpoint name with current datetime to avoid conflicts\n",
    "import datetime\n",
    "\n",
    "online_endpoint_name = \"endpoint-gpu\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
    "\n",
    "# create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    description=\"this is a sample online endpoint\",\n",
    "    auth_mode=\"key\",\n",
    "    tags={\"foo\": \"bar\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Create the endpoint\n",
    "Using the `MLClient` created earlier, we will now create the Endpoint in the workspace. This command will start the endpoint creation and return a confirmation response while the endpoint creation continues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://endpoint-gpu10090133451811.canadacentral.inference.ml.azure.com/score', 'openapi_uri': 'https://endpoint-gpu10090133451811.canadacentral.inference.ml.azure.com/swagger.json', 'name': 'endpoint-gpu10090133451811', 'description': 'this is a sample online endpoint', 'tags': {'foo': 'bar'}, 'properties': {'createdBy': 'System Administrator', 'createdAt': '2025-10-09T01:33:47.114993+0000', 'lastModifiedAt': '2025-10-09T01:33:47.114993+0000', 'azureml.onlineendpointid': '/subscriptions/5784b6a5-de3f-4fa4-8b8f-e5bb70ff6b25/resourcegroups/rg-aml-ws-prod-cc-01/providers/microsoft.machinelearningservices/workspaces/mlwprodcc01/onlineendpoints/endpoint-gpu10090133451811', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/5784b6a5-de3f-4fa4-8b8f-e5bb70ff6b25/providers/Microsoft.MachineLearningServices/locations/canadacentral/mfeOperationsStatus/oeidp:fb55c029-0b65-4245-a314-9f559e264f56:ce9e3c90-d48e-4207-80ba-44a7b5805bd0?api-version=2022-02-01-preview'}, 'print_as_yaml': False, 'id': '/subscriptions/5784b6a5-de3f-4fa4-8b8f-e5bb70ff6b25/resourceGroups/rg-aml-ws-prod-cc-01/providers/Microsoft.MachineLearningServices/workspaces/mlwprodcc01/onlineEndpoints/endpoint-gpu10090133451811', 'Resource__source_path': '', 'base_path': 'c:\\\\Users\\\\mlopsuser\\\\Documents\\\\GitHub\\\\MLOPs-AzureML\\\\notebooks\\\\deployments\\\\online\\\\custom_image', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x0000020CD8F430E0>, 'auth_mode': 'key', 'location': 'canadacentral', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x0000020CD8FC42B0>, 'traffic': {}, 'mirror_traffic': {}, 'kind': 'Managed'})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Configure online deployment\n",
    "A deployment is a set of resources required for hosting the model that does the actual inferencing. We will create a deployment for our endpoint using the `ManagedOnlineDeployment` class.\n",
    "\n",
    "### Key aspects of deployment \n",
    "- `name` - Name of the deployment.\n",
    "- `endpoint_name` - Name of the endpoint to create the deployment under.\n",
    "- `model` - The model to use for the deployment. This value can be either a reference to an existing versioned model in the workspace or an inline model specification.\n",
    "- `environment` - The environment to use for the deployment. This value can be either a reference to an existing versioned environment in the workspace or an inline environment specification.\n",
    "- `code_configuration` - the configuration for the source code and scoring script\n",
    "    - `path`- Path to the source code directory for scoring the model\n",
    "    - `scoring_script` - Relative path to the scoring file in the source code directory\n",
    "- `instance_type` - The VM size to use for the deployment. For the list of supported sizes, see [Managed online endpoints SKU list](https://docs.microsoft.com/en-us/azure/machine-learning/reference-managed-online-endpoints-vm-sku-list).\n",
    "- `instance_count` - The number of instances to use for the deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a GPU deployment backed by the tfservingcustom model\n",
    "try:\n",
    "    model = ml_client.models.get(name=\"tfservingcustom\", version=str(registered_model.version))\n",
    "    model_version = registered_model.version\n",
    "except NameError:\n",
    "    latest_model = list(ml_client.models.list(name=\"tfservingcustom\"))\n",
    "    if not latest_model:\n",
    "        raise RuntimeError(\"No registered model named tfservingcustom found. Run step 2 first.\")\n",
    "    latest_model = sorted(latest_model, key=lambda m: int(m.version), reverse=True)[0]\n",
    "    model = latest_model\n",
    "    model_version = latest_model.version\n",
    "\n",
    "model_mount_base = f\"/var/azureml-app/azureml-models/{model.name}/{model_version}\"\n",
    "\n",
    "env = Environment(\n",
    "    image=\"docker.io/tensorflow/serving:latest\",\n",
    "    inference_config={\n",
    "        \"liveness_route\": {\"port\": 8501, \"path\": \"/v1/models/half_plus_two\"},\n",
    "        \"readiness_route\": {\"port\": 8501, \"path\": \"/v1/models/half_plus_two\"},\n",
    "        \"scoring_route\": {\"port\": 8501, \"path\": \"/v1/models/half_plus_two:predict\"},\n",
    "    },\n",
    ")\n",
    "\n",
    "environment_variables = {\n",
    "    \"MODEL_BASE_PATH\": model_mount_base,\n",
    "    \"MODEL_NAME\": \"half_plus_two\",\n",
    "}\n",
    "\n",
    "print(\"Using model:\", model.name, \"version\", model_version)\n",
    "print(\"MODEL_BASE_PATH:\", environment_variables[\"MODEL_BASE_PATH\"])\n",
    "\n",
    "blue_deployment = ManagedOnlineDeployment(\n",
    "    name=\"orange\",\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=model,\n",
    "    environment=env,\n",
    "    environment_variables=environment_variables,\n",
    "    instance_type=\"Standard_F2s_v2\",\n",
    "    instance_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect packaged model structure before deployment\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Packaged model directory structure:\")\n",
    "for path in sorted(Path(\"tfservingcustom_serving\").rglob(\"*\")):\n",
    "    rel = path.relative_to(\"tfservingcustom_serving\")\n",
    "    if path.is_dir():\n",
    "        print(f\"  [DIR] {rel}\")\n",
    "    else:\n",
    "        print(f\"  [FILE] {rel}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Readiness route vs. liveness route\n",
    "An HTTP server defines paths for both liveness and readiness. A liveness route is used to check whether the server is running. A readiness route is used to check whether the server is ready to do work. In machine learning inference, a server could respond 200 OK to a liveness request before loading a model. The server could respond 200 OK to a readiness request only after the model has been loaded into memory.\n",
    "\n",
    "Review the [Kubernetes documentation](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/) for more information about liveness and readiness probes.\n",
    "\n",
    "Notice that this deployment uses the same path for both liveness and readiness, since TF Serving only defines a liveness route."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Create the deployment\n",
    "Using the `MLClient` created earlier, we will now create the deployment in the workspace. This command will start the deployment creation and return a confirmation response while the deployment creation continues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check: endpoint endpoint-gpu10090056098905 exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................................................................................................."
     ]
    },
    {
     "ename": "HttpResponseError",
     "evalue": "(ResourceNotReady) User container has crashed or terminated: Liveness probe failed: Get . Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-resourcenotready\nCode: ResourceNotReady\nMessage: User container has crashed or terminated: Liveness probe failed: Get . Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-resourcenotready",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationFailed\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Miniconda\\envs\\MLOps\\Lib\\site-packages\\azure\\core\\polling\\base_polling.py:805\u001b[39m, in \u001b[36mLROBasePolling.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m805\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    807\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m BadStatus \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Miniconda\\envs\\MLOps\\Lib\\site-packages\\azure\\core\\polling\\base_polling.py:837\u001b[39m, in \u001b[36mLROBasePolling._poll\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    836\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _failed(\u001b[38;5;28mself\u001b[39m.status()):\n\u001b[32m--> \u001b[39m\u001b[32m837\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OperationFailed(\u001b[33m\"\u001b[39m\u001b[33mOperation failed or canceled\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    839\u001b[39m final_get_url = \u001b[38;5;28mself\u001b[39m._operation.get_final_get_url(\u001b[38;5;28mself\u001b[39m._pipeline_response)\n",
      "\u001b[31mOperationFailed\u001b[39m: Operation failed or canceled",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mHttpResponseError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mml_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin_create_or_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblue_deployment\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Miniconda\\envs\\MLOps\\Lib\\site-packages\\azure\\core\\polling\\_poller.py:326\u001b[39m, in \u001b[36mLROPoller.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> PollingReturnType_co:\n\u001b[32m    318\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the result of the long running operation, or\u001b[39;00m\n\u001b[32m    319\u001b[39m \u001b[33;03m    the result available after the specified timeout.\u001b[39;00m\n\u001b[32m    320\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    324\u001b[39m \u001b[33;03m    :raises ~azure.core.exceptions.HttpResponseError: Server problem with the query.\u001b[39;00m\n\u001b[32m    325\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    327\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._polling_method.resource()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Miniconda\\envs\\MLOps\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py:138\u001b[39m, in \u001b[36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    136\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m span_attributes.items():\n\u001b[32m    137\u001b[39m                 span.add_attribute(key, value)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# Native path\u001b[39;00m\n\u001b[32m    141\u001b[39m     config = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Miniconda\\envs\\MLOps\\Lib\\site-packages\\azure\\core\\polling\\_poller.py:345\u001b[39m, in \u001b[36mLROPoller.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    341\u001b[39m \u001b[38;5;28mself\u001b[39m._thread.join(timeout=timeout)\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    343\u001b[39m     \u001b[38;5;66;03m# Let's handle possible None in forgiveness here\u001b[39;00m\n\u001b[32m    344\u001b[39m     \u001b[38;5;66;03m# https://github.com/python/mypy/issues/8165\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# Was None\u001b[39;00m\n\u001b[32m    347\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Miniconda\\envs\\MLOps\\Lib\\site-packages\\azure\\core\\polling\\_poller.py:250\u001b[39m, in \u001b[36mLROPoller._start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Start the long running operation.\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mOn completion, runs any callbacks.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_polling_method\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m AzureError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m    252\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m error.continuation_token:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Miniconda\\envs\\MLOps\\Lib\\site-packages\\azure\\core\\polling\\base_polling.py:820\u001b[39m, in \u001b[36mLROBasePolling.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    813\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(\n\u001b[32m    814\u001b[39m         response=\u001b[38;5;28mself\u001b[39m._pipeline_response.http_response,\n\u001b[32m    815\u001b[39m         message=\u001b[38;5;28mstr\u001b[39m(err),\n\u001b[32m    816\u001b[39m         error=err,\n\u001b[32m    817\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    819\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m OperationFailed \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response=\u001b[38;5;28mself\u001b[39m._pipeline_response.http_response, error=err) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
      "\u001b[31mHttpResponseError\u001b[39m: (ResourceNotReady) User container has crashed or terminated: Liveness probe failed: Get . Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-resourcenotready\nCode: ResourceNotReady\nMessage: User container has crashed or terminated: Liveness probe failed: Get . Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-resourcenotready"
     ]
    }
   ],
   "source": [
    "ml_client.begin_create_or_update(blue_deployment).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blue deployment takes 100 traffic\n",
    "endpoint.traffic = {\"blue\": 100}\n",
    "ml_client.begin_create_or_update(endpoint).result()\n",
    "\n",
    "#endpoint.traffic = {\"blue\": 0, \"green\": 0, \"orange\": 100}\n",
    "#ml_client.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Test the endpoint with sample data\n",
    "Using the `MLClient` created earlier, we will get a handle to the endpoint. The endpoint can be invoked using the `invoke` command with the following parameters:\n",
    "- `endpoint_name` - Name of the endpoint\n",
    "- `request_file` - File with request data\n",
    "- `deployment_name` - Name of the specific deployment to test in an endpoint\n",
    "\n",
    "We will send a sample request using a [json](./model-1/sample-request.json) file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"predictions\": [2.5, 3.0, 4.5\\n    ]\\n}'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the blue deployment with some sample data\n",
    "ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    deployment_name=\"orange\",\n",
    "    request_file=\"sample-request.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Managing endpoints and deployments\n",
    "\n",
    "## 6.1 Get details of the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the details for online endpoint\n",
    "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
    "\n",
    "# existing traffic details\n",
    "print(endpoint.traffic)\n",
    "\n",
    "# Get the scoring URI\n",
    "print(endpoint.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Get the logs for the new deployment\n",
    "Get the logs for the green deployment and verify as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.online_deployments.get_logs(\n",
    "    name=\"blue\", endpoint_name=online_endpoint_name, lines=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Delete the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ml_client.online_endpoints.begin_delete(name=online_endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "description": {
   "description": "Deploy a custom container as an online endpoint. Use web servers other than the default Python Flask server used by Azure ML without losing the benefits of Azure ML's built-in monitoring, scaling, alerting, and authentication."
  },
  "kernelspec": {
   "display_name": "MLOps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
