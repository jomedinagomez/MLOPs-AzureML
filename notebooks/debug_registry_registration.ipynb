{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8aa3f10",
   "metadata": {},
   "source": [
    "# Azure ML Registry Registration Debug Notebook\n",
    "\n",
    "This notebook investigates why Azure ML model registration works in notebooks but fails in pipelines when using the same managed identity.\n",
    "\n",
    "## Purpose\n",
    "- Compare authentication contexts between notebook and pipeline environments\n",
    "- Test model registration scenarios with managed identity\n",
    "- Identify differences that cause pipeline failures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1358a058",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "Import Azure ML SDK, authentication libraries, and other required packages for model registration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b964227e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Azure ML SDK and authentication libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "from azure.identity import DefaultAzureCredential, ManagedIdentityCredential, AzureCliCredential\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "# Print environment info for debugging\n",
    "print(\"Environment Variables:\")\n",
    "print(f\"DEFAULT_IDENTITY_CLIENT_ID: {os.environ.get('DEFAULT_IDENTITY_CLIENT_ID', 'NOT SET')}\")\n",
    "print(f\"MSI_ENDPOINT: {os.environ.get('MSI_ENDPOINT', 'NOT SET')}\")\n",
    "print(f\"IDENTITY_ENDPOINT: {os.environ.get('IDENTITY_ENDPOINT', 'NOT SET')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d0d0d6",
   "metadata": {},
   "source": [
    "## 2. Set Up Azure ML Client with Managed Identity\n",
    "Configure ManagedIdentityCredential and create MLClient instances for workspace and registry access using compute managed identity.\n",
    "\n",
    "This section replicates the authentication approach used in the pipeline to identify context differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a810d919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up authentication - using same approach as pipeline\n",
    "print(\"Setting up authentication...\")\n",
    "\n",
    "# Get managed identity client ID (same as pipeline)\n",
    "msi_client_id = os.environ.get(\"DEFAULT_IDENTITY_CLIENT_ID\")\n",
    "print(f\"Using MSI Client ID: {msi_client_id}\")\n",
    "\n",
    "# Create credential (same as pipeline)\n",
    "credential = ManagedIdentityCredential(client_id=msi_client_id)\n",
    "\n",
    "# Test credential access\n",
    "try:\n",
    "    token = credential.get_token(\"https://management.azure.com/.default\")\n",
    "    print(\"‚úÖ Managed identity authentication successful\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Managed identity authentication failed: {e}\")\n",
    "\n",
    "# Set up workspace connection details\n",
    "subscription_id = \"5784b6a5-de3f-4fa4-8b8f-e5bb70ff6b25\"\n",
    "resource_group = \"rgamlcc001\"\n",
    "workspace_name = \"amldevcc001\"\n",
    "registry_name = \"amlrdevcc001\"\n",
    "\n",
    "print(f\"Workspace: {workspace_name}\")\n",
    "print(f\"Registry: {registry_name}\")\n",
    "\n",
    "# Create MLClient for workspace\n",
    "ml_client_workspace = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=subscription_id,\n",
    "    resource_group_name=resource_group,\n",
    "    workspace_name=workspace_name\n",
    ")\n",
    "\n",
    "# Create MLClient for registry\n",
    "ml_client_registry = MLClient(\n",
    "    credential=credential,\n",
    "    registry_name=registry_name\n",
    ")\n",
    "\n",
    "print(\"‚úÖ MLClients created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff0de10",
   "metadata": {},
   "source": [
    "## 3. Test Registry Access\n",
    "Test the same registry access patterns used in the pipeline to identify differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4385c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test registry access - same as pipeline code\n",
    "print(\"Testing registry access...\")\n",
    "\n",
    "try:\n",
    "    # Test registry listing (same as pipeline)\n",
    "    models_list = list(ml_client_registry.models.list())\n",
    "    print(f\"‚úÖ Registry access successful - found {len(models_list)} models\")\n",
    "    \n",
    "    # Print first few models for verification\n",
    "    for i, model in enumerate(models_list[:3]):\n",
    "        print(f\"  Model {i+1}: {model.name} (v{model.version})\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Registry access failed: {e}\")\n",
    "\n",
    "# Test workspace access for comparison\n",
    "print(\"\\nTesting workspace access...\")\n",
    "try:\n",
    "    workspace_models = list(ml_client_workspace.models.list())\n",
    "    print(f\"‚úÖ Workspace access successful - found {len(workspace_models)} models\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Workspace access failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0f3045",
   "metadata": {},
   "source": [
    "## 4. Test Model Registration to Registry\n",
    "Create a simple test model and attempt to register it to the registry using the same logic as the pipeline.\n",
    "\n",
    "**Key Question**: Does this work in the notebook context but fail in pipeline context?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00abd279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test model registration using local model folder path\n",
    "# This matches the pipeline scenario using local assets\n",
    "\n",
    "print(\"üß™ Testing registry registration with local model folder...\")\n",
    "\n",
    "# Define the local model path - using your actual model location\n",
    "model_path = \"assets_sharing/artifacts/model\"\n",
    "\n",
    "print(f\"Using local model path: {model_path}\")\n",
    "\n",
    "# Check if the model path exists\n",
    "import os\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"‚úÖ Model path exists: {model_path}\")\n",
    "    # List contents if it's a directory\n",
    "    if os.path.isdir(model_path):\n",
    "        contents = os.listdir(model_path)\n",
    "        print(f\"   Contents: {contents[:5]}...\")  # Show first 5 items\n",
    "        \n",
    "        # Check for MLflow model files\n",
    "        if \"MLmodel\" in contents:\n",
    "            print(f\"   ‚úÖ MLflow model file found!\")\n",
    "        if \"model.pkl\" in contents or any(f.endswith('.pkl') for f in contents):\n",
    "            print(f\"   ‚úÖ Model pickle file found!\")\n",
    "        if \"conda.yaml\" in contents:\n",
    "            print(f\"   ‚úÖ Conda environment file found!\")\n",
    "else:\n",
    "    print(f\"‚ùå Model path does not exist: {model_path}\")\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "    print(f\"Available files/folders:\")\n",
    "    try:\n",
    "        for item in os.listdir(\".\"):\n",
    "            print(f\"   {item}\")\n",
    "        \n",
    "        # Check if assets_sharing folder exists\n",
    "        if os.path.exists(\"assets_sharing\"):\n",
    "            print(f\"\\n   assets_sharing folder contents:\")\n",
    "            for item in os.listdir(\"assets_sharing\"):\n",
    "                print(f\"     {item}\")\n",
    "                if item == \"artifacts\" and os.path.isdir(\"assets_sharing/artifacts\"):\n",
    "                    print(f\"       artifacts folder contents:\")\n",
    "                    for subitem in os.listdir(\"assets_sharing/artifacts\"):\n",
    "                        print(f\"         {subitem}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   Could not list directories: {e}\")\n",
    "\n",
    "try:\n",
    "    # Create a new Model object for registry registration (same as pipeline logic)\n",
    "    model_for_registry = Model(\n",
    "        path=model_path,  # Use your actual model folder\n",
    "        name=\"notebook-test-assets-model\",  # Test name\n",
    "        description=\"Test model registered from notebook using assets_sharing folder with managed identity\",\n",
    "        type=AssetTypes.MLFLOW_MODEL\n",
    "    )\n",
    "    \n",
    "    print(f\"Attempting to register model: {model_for_registry.name}\")\n",
    "    print(f\"Model path: {model_path}\")\n",
    "    \n",
    "    # This is the exact same call that fails in the pipeline\n",
    "    registered_model = ml_client_registry.models.create_or_update(model_for_registry)\n",
    "    print(f\"‚úÖ SUCCESS: Model registered to registry from notebook!\")\n",
    "    print(f\"   Registered model: {registered_model.name} (v{registered_model.version})\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Registry registration failed: {e}\")\n",
    "    print(f\"Error type: {type(e).__name__}\")\n",
    "    \n",
    "    # Print detailed error info\n",
    "    if hasattr(e, 'error_code'):\n",
    "        print(f\"Error code: {e.error_code}\")\n",
    "    if hasattr(e, 'message'):\n",
    "        print(f\"Error message: {e.message}\")\n",
    "    \n",
    "    # Additional debugging - check if it's a path issue\n",
    "    print(f\"\\nüîç Debugging model path access:\")\n",
    "    try:\n",
    "        # Try to create the model object without registering\n",
    "        test_model = Model(\n",
    "            path=model_path,\n",
    "            name=\"test-path-only\",\n",
    "            description=\"Test path access only\",\n",
    "            type=AssetTypes.MLFLOW_MODEL\n",
    "        )\n",
    "        print(f\"‚úÖ Model object creation successful\")\n",
    "    except Exception as path_error:\n",
    "        print(f\"‚ùå Model object creation failed: {path_error}\")\n",
    "\n",
    "# Test with workspace registration first (to verify the model works)\n",
    "print(f\"\\nüîÑ Testing workspace registration with same local model...\")\n",
    "try:\n",
    "    model_for_workspace = Model(\n",
    "        path=model_path,\n",
    "        name=\"notebook-test-workspace-assets\",\n",
    "        description=\"Test model registered to workspace from notebook using assets_sharing folder\",\n",
    "        type=AssetTypes.MLFLOW_MODEL\n",
    "    )\n",
    "    \n",
    "    workspace_registered = ml_client_workspace.models.create_or_update(model_for_workspace)\n",
    "    print(f\"‚úÖ Workspace registration successful: {workspace_registered.name} (v{workspace_registered.version})\")\n",
    "    \n",
    "except Exception as ws_error:\n",
    "    print(f\"‚ùå Workspace registration also failed: {ws_error}\")\n",
    "    print(f\"This suggests a model path or format issue, not a registry-specific problem\")\n",
    "\n",
    "print(f\"\\nüí° Using your model path: {model_path}\")\n",
    "print(f\"   This should match exactly what your pipeline uses!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b0c9cf",
   "metadata": {},
   "source": [
    "## 5. Environment Context Analysis\n",
    "Compare the execution environment between notebook and pipeline contexts to identify potential differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4b26d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze environment differences between notebook and pipeline\n",
    "print(\"=== ENVIRONMENT ANALYSIS ===\")\n",
    "\n",
    "print(f\"\\nüìç Execution Context:\")\n",
    "print(f\"  Current working directory: {os.getcwd()}\")\n",
    "print(f\"  Python executable: {os.sys.executable}\")\n",
    "print(f\"  Platform: {os.sys.platform}\")\n",
    "\n",
    "print(f\"\\nüîê Authentication Context:\")\n",
    "print(f\"  MSI Client ID: {os.environ.get('DEFAULT_IDENTITY_CLIENT_ID', 'NOT SET')}\")\n",
    "print(f\"  MSI Endpoint: {os.environ.get('MSI_ENDPOINT', 'NOT SET')}\")\n",
    "print(f\"  Identity Endpoint: {os.environ.get('IDENTITY_ENDPOINT', 'NOT SET')}\")\n",
    "print(f\"  Azure Client ID: {os.environ.get('AZURE_CLIENT_ID', 'NOT SET')}\")\n",
    "\n",
    "print(f\"\\nüåê Network Context:\")\n",
    "import socket\n",
    "hostname = socket.gethostname()\n",
    "print(f\"  Hostname: {hostname}\")\n",
    "\n",
    "# Check if we're in a pipeline context\n",
    "print(f\"\\nüîç Pipeline Context Detection:\")\n",
    "pipeline_vars = [\n",
    "    'AZUREML_RUN_ID',\n",
    "    'AZUREML_EXPERIMENT_ID', \n",
    "    'AZUREML_ROOT_RUN_ID',\n",
    "    'AZUREML_RUN_TOKEN',\n",
    "    'AZUREML_ARM_SUBSCRIPTION',\n",
    "    'AZUREML_ARM_RESOURCEGROUP',\n",
    "    'AZUREML_ARM_WORKSPACE_NAME'\n",
    "]\n",
    "\n",
    "for var in pipeline_vars:\n",
    "    value = os.environ.get(var, 'NOT SET')\n",
    "    print(f\"  {var}: {value}\")\n",
    "\n",
    "# Check Azure ML context\n",
    "print(f\"\\nüìä Azure ML Context:\")\n",
    "try:\n",
    "    from azureml.core import Run\n",
    "    run = Run.get_context()\n",
    "    if hasattr(run, 'id'):\n",
    "        print(f\"  Run ID: {run.id}\")\n",
    "        print(f\"  Experiment: {run.experiment.name}\")\n",
    "        print(f\"  Run Type: {type(run).__name__}\")\n",
    "    else:\n",
    "        print(\"  Not in an Azure ML Run context\")\n",
    "except:\n",
    "    print(\"  Could not get Azure ML Run context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4899e5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if compute cluster is configured for image builds\n",
    "print(\"=== IMAGE BUILD CONFIGURATION CHECK ===\")\n",
    "\n",
    "try:\n",
    "    # Get workspace details to check image build compute setting\n",
    "    workspace_details = ml_client_workspace.workspaces.get(workspace_name)\n",
    "    \n",
    "    # Check if imageBuildCompute is configured\n",
    "    if hasattr(workspace_details, 'image_build_compute') and workspace_details.image_build_compute:\n",
    "        print(f\"‚úÖ Image build compute configured: {workspace_details.image_build_compute}\")\n",
    "    else:\n",
    "        print(\"‚ùå No image build compute configured - will use serverless\")\n",
    "        \n",
    "    # List available compute targets\n",
    "    print(f\"\\nüìä Available Compute Targets:\")\n",
    "    compute_list = list(ml_client_workspace.compute.list())\n",
    "    for compute in compute_list:\n",
    "        print(f\"  - {compute.name} ({compute.type}) - State: {compute.provisioning_state}\")\n",
    "        \n",
    "    # Check specifically for cpu-cluster-uami\n",
    "    cpu_cluster = None\n",
    "    try:\n",
    "        cpu_cluster = ml_client_workspace.compute.get(\"cpu-cluster-uami\")\n",
    "        print(f\"\\nüéØ cpu-cluster-uami Details:\")\n",
    "        print(f\"  Type: {cpu_cluster.type}\")\n",
    "        print(f\"  State: {cpu_cluster.provisioning_state}\")\n",
    "        print(f\"  VM Size: {cpu_cluster.size}\")\n",
    "        print(f\"  Min Nodes: {cpu_cluster.scale_settings.min_node_count}\")\n",
    "        print(f\"  Max Nodes: {cpu_cluster.scale_settings.max_node_count}\")\n",
    "        \n",
    "        # Check if this cluster can be used for image builds\n",
    "        if cpu_cluster.provisioning_state == \"Succeeded\":\n",
    "            print(f\"  ‚úÖ Cluster is ready and can be used for image builds\")\n",
    "        else:\n",
    "            print(f\"  ‚ö†Ô∏è Cluster state: {cpu_cluster.provisioning_state}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not get cpu-cluster-uami details: {e}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error checking workspace configuration: {e}\")\n",
    "\n",
    "# Alternative check using Azure CLI if available\n",
    "print(f\"\\nüîç Alternative Check - Using Azure CLI:\")\n",
    "try:\n",
    "    import subprocess\n",
    "    result = subprocess.run([\n",
    "        \"az\", \"ml\", \"workspace\", \"show\", \n",
    "        \"--name\", workspace_name,\n",
    "        \"--resource-group\", resource_group,\n",
    "        \"--query\", \"imageBuildCompute\",\n",
    "        \"--output\", \"tsv\"\n",
    "    ], capture_output=True, text=True, timeout=30)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        image_build_compute = result.stdout.strip()\n",
    "        if image_build_compute and image_build_compute != \"None\":\n",
    "            print(f\"‚úÖ CLI confirms image build compute: {image_build_compute}\")\n",
    "        else:\n",
    "            print(\"‚ùå CLI shows no image build compute configured\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è CLI check failed: {result.stderr}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not run Azure CLI check: {e}\")\n",
    "\n",
    "print(f\"\\nüí° Summary:\")\n",
    "print(f\"- If image build compute is configured ‚Üí Your cluster will handle image builds\")\n",
    "print(f\"- If not configured ‚Üí Azure ML uses serverless compute for image preparation\")\n",
    "print(f\"- The 'prepare image' job you see is normal and expected!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9936827d",
   "metadata": {},
   "source": [
    "## 6. Conclusions and Next Steps\n",
    "\n",
    "Based on the results above, we can determine:\n",
    "\n",
    "### Key Findings:\n",
    "1. **Authentication**: Does managed identity work the same in both contexts?\n",
    "2. **Registry Access**: Can we list models from registry in notebook vs pipeline?\n",
    "3. **Model Registration**: Does registry registration succeed in notebook but fail in pipeline?\n",
    "\n",
    "### Potential Differences:\n",
    "- **Network Context**: Different network routes or proxy settings\n",
    "- **Environment Variables**: Missing or different environment variables in pipeline\n",
    "- **Azure ML Context**: Different Azure ML Run contexts affecting model path resolution\n",
    "- **File Path Resolution**: Different working directories or model path handling\n",
    "\n",
    "### Next Actions:\n",
    "If registry registration works in the notebook but fails in the pipeline with the same managed identity, the issue is likely:\n",
    "1. **Path Resolution**: Pipeline and notebook resolve model paths differently\n",
    "2. **Network Routing**: Different network paths to registry storage\n",
    "3. **Azure ML Context**: Pipeline context affects how model URLs are constructed\n",
    "\n",
    "Run this notebook on your compute instance to compare results with the pipeline execution!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-azureml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
